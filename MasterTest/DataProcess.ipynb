{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              BMH ZZLLM   ZZLLMC ZZLLKDDM  ZZLLKDMC ZZLLKCBH ZZLLZWH WGYM  \\\n",
      "0       611689959   199  管理类综合能力     6116      西北大学       99       1  204   \n",
      "1       510296397   101   思想政治理论     6152    西安翻译学院       11      18  204   \n",
      "2       610397518   101   思想政治理论     6103    西安石油大学       62      26  201   \n",
      "3       610797013   101   思想政治理论     6107    西安邮电大学       24       6  201   \n",
      "4       614698996   101   思想政治理论     6146      西京学院       74      28  204   \n",
      "...           ...   ...      ...      ...       ...      ...     ...  ...   \n",
      "172883  653398263   101   思想政治理论     6156    咸阳师范学院      105      11  201   \n",
      "172884  653399631   101   思想政治理论     6149      安康学院      059      20  201   \n",
      "172885  653399955   101   思想政治理论     6144    宝鸡文理学院      J31      11  204   \n",
      "172886  653499532   101   思想政治理论     6141    陕西理工大学      144      28  201   \n",
      "172887  653499807   101   思想政治理论     6134  西安建筑科技大学      302      09  201   \n",
      "\n",
      "        WGYMC WGYKDDM  ... YWK2KCBH YWK2ZWH BKDWDM        BKDWMC  BKZYDM  \\\n",
      "0       英语（二）    6116  ...       99       1  10697          西北大学  125500   \n",
      "1       英语（二）    6152  ...       11      18  10613        西南交通大学  086100   \n",
      "2       英语（一）    6103  ...       62      26  85302  自然资源部第二海洋研究所  070704   \n",
      "3       英语（一）    6107  ...       24       6  11482        浙江财经大学  020203   \n",
      "4       英语（二）    6146  ...       74      28  11482        浙江财经大学  025300   \n",
      "...       ...     ...  ...      ...     ...    ...           ...     ...   \n",
      "172883  英语（一）    6156  ...      105      11  10726        西北政法大学  035101   \n",
      "172884  英语（一）    6149  ...      059      20  10719          延安大学  050100   \n",
      "172885  英语（二）    6144  ...      J31      11  10651        西南财经大学  025400   \n",
      "172886  英语（一）    6141  ...      144      28  11414    中国石油大学(北京)  082000   \n",
      "172887  英语（一）    6134  ...      302      09  10718        陕西师范大学  040303   \n",
      "\n",
      "          BKZYMC PROVINCE CITY AREA _NullFlags  \n",
      "0           图书情报      陕西省  西安市  长安区    b'\\x00'  \n",
      "1           交通运输      陕西省  西安市  鄠邑区    b'\\x00'  \n",
      "2           海洋地质      陕西省  西安市  鄠邑区    b'\\x00'  \n",
      "3            财政学      陕西省  西安市  长安区    b'\\x00'  \n",
      "4             税务      陕西省  西安市  长安区    b'\\x00'  \n",
      "...          ...      ...  ...  ...        ...  \n",
      "172883   法律（非法学）                       b'\\x07'  \n",
      "172884    中国语言文学      陕西省  安康市  汉滨区    b'\\x00'  \n",
      "172885      国际商务      陕西省  宝鸡市  金台区    b'\\x00'  \n",
      "172886  石油与天然气工程                       b'\\x07'  \n",
      "172887   体育教育训练学                       b'\\x07'  \n",
      "\n",
      "[172888 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "path = 'D:\\\\IPMIProject\\\\master test\\\\20231223.dbf' # 文件目录\n",
    "table = DBF(path, encoding='GBK')\n",
    "df = pd.DataFrame(iter(table))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理尝试\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "allowed_values1 = ['101','109','199']\n",
    "allowed_values2 = ['201','202','203','204']\n",
    "allowed_values3 = ['301','302','303','306','307','311','312','313','314','315','333','396','397','398']\n",
    "allowed_values4 = ['408','414','415','497','498']\n",
    "df.loc[~df['ZZLLM'].isin(allowed_values1), 'ZZLLM'] = '000'\n",
    "df.loc[~df['WGYM'].isin(allowed_values2), 'WGYM'] = '000'\n",
    "df.loc[~df['YWK1M'].isin(allowed_values3), 'YWK1M'] = '000'\n",
    "df.loc[~df['YWK2M'].isin(allowed_values4), 'YWK2M'] = '000'\n",
    "df.columns = df.columns.map(str.lower)\n",
    "arr = df\n",
    "# print(arr.head(10))\n",
    "\n",
    "# [\"bmh\",\"zzllm\",\"wgym\",\"ywk1m\",\"ywk2m\",\"bkdwdm\"]\n",
    "# 取出dataframe的几列\n",
    "df1 = arr[[\"bmh\",\"zzllm\",\"wgym\",\"ywk1m\",\"ywk2m\",\"bkdwdm\"]]\n",
    "\n",
    "# 使用其中的四个属性进行分组\n",
    "df2 = df1.groupby([\"zzllm\",\"wgym\",\"ywk1m\",\"ywk2m\"]).count()\n",
    "df2.to_excel(\"classfier.xlsx\")\n",
    "\n",
    "\n",
    "# sub_DF=[arr[arr['wgymc'].isin([i])] for i in np.unique(arr['wgymc'])]\n",
    "# print(df2.head())\n",
    "# groupby后的数据要先转为dataframe，再进行索引重建，才可以保存为xlsx\n",
    "# class_arr = pd.DataFrame(df1.groupby([\"zzllmc\",\"wgymc\",\"ywk1mc\",\"ywk2mc\"]))\n",
    "# class_arr.reset_index(inplace=True)\n",
    "# class_arr.to_excel(\"res.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照外国语考点代码拆分数据\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# arr = pd.read_excel(\"tmp.xlsx\")\n",
    "list1 = arr['wgykddm'].unique()\n",
    "groups = arr.groupby(\"wgykddm\")\n",
    "for i in arr['wgykddm'].unique():\n",
    "    groups.get_group(i).to_excel(str(i)+\".xlsx\")\n",
    "# print(groups['wgykddm'])\n",
    "    # 检查数量是否相等\n",
    "# print(arr.shape)#(16383,32)\n",
    "# sum = 0;\n",
    "# for i in arr['wgykddm'].unique():\n",
    "#     df1 = pd.read_excel(str(i)+\".xlsx\")\n",
    "#     sum += df1.shape[0]\n",
    "\n",
    "# print(sum)#16383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "      zzllkddm zzllkcbh  renshu\n",
      "0         6103        1      30\n",
      "1         6103       10      30\n",
      "2         6103      100      30\n",
      "3         6103      101      30\n",
      "4         6103      102      30\n",
      "...        ...      ...     ...\n",
      "5420      6160      103      30\n",
      "5421      6160      104      30\n",
      "5422      6160      105      30\n",
      "5423      6160      106      30\n",
      "5424      6160      107      16\n",
      "\n",
      "[5425 rows x 3 columns]\n",
      "[30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 29, 30, 30, 30, 31, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 26, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 29, 28, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 21, 30, 30, 30, 30, 30]\n"
     ]
    }
   ],
   "source": [
    "# 统计每个考点教室所能容纳的人数\n",
    "groups1 = pd.read_excel(\"考场容量表.xls\").groupby(\"zzllkddm\")\n",
    "print(groups1.apply(lambda x:x))\n",
    "print(groups1.get_group(6103)[\"renshu\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个考点有多少专业，以及每个专业有多少人，参考属性有[\"zzllmc\",\"wgymc\",\"ywk1mc\",\"ywk2mc\",\"bkdwdm\"]\n",
    "\n",
    "for i in arr['wgykddm'].unique():\n",
    "    df1 = pd.read_excel(str(i)+\".xlsx\")\n",
    "\n",
    "    # 使用其中的四个属性进行分组,\"bkdwdm\"\n",
    "    df2 = df1.groupby([\"zzllm\",\"wgym\",\"ywk1m\",\"ywk2m\"]).count()\n",
    "    df2.to_excel(\"classfier\"+str(i)+\".xlsx\")\n",
    "\n",
    "# 结果里面bmh表示的是每个专业的人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6116' '6152' '6103' '6107' '6146' '6144' '6143' '6139' '6117' '6153'\n",
      " '6118' '6160' '6141' '6114' '6113' '6124' '6134' '6105' '6136' '6149'\n",
      " '6159' '6157' '6151' '6115' '6112' '6111' '6156' '6133' '6148' '6140'\n",
      " '6125' '6154' '6147' '6150' '6145' '6127' '6138' '6128' '6122' '6129'\n",
      " '6130' '6131' '6142' '6158']\n",
      "172888\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理、提取出每个考点，每个专业的人数\n",
    "sums = 0\n",
    "print(list1)\n",
    "for i in list1:\n",
    "    # .fillna(method=\"ffill\")向下填充\n",
    "    res = pd.read_excel(\"classfier\"+str(i)+\".xlsx\").fillna(method=\"ffill\")\n",
    "    # dataframe按各专业人数一列排序，inplace原地排序，ascending升序\n",
    "    # res.sort_values(by=\"bmh\",inplace=True,ascending=False)\n",
    "    # 取出各专业人数一列转为array\n",
    "    # 若存在控制需要填充\n",
    "    # res = res.fillna(res['bmh'].mean())\n",
    "    StuNum = res[['zzllmc','wgymc','ywk1mc','ywk2mc','bmh']]\n",
    "    np.savetxt(\"classfier\"+str(i)+\".txt\",StuNum,fmt=\"%s,%s,%s,%s,%s\",delimiter=\" \")\n",
    "    sums += res['bmh'].sum()\n",
    "\n",
    "print(sums)\n",
    "\n",
    "# classfierX.excel中的前四列可以映射到对应的专业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sum_matrix(matrix):\n",
    "    sum=0\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix[i])):\n",
    "            sum+=matrix[i][j]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       s1     s2     s3   s4   num\n",
      "0   101.0    0.0    0.0    0    67\n",
      "1     NaN    NaN  301.0    0     1\n",
      "2     NaN  201.0    0.0    0   747\n",
      "3     NaN    NaN  301.0    0   835\n",
      "4     NaN    NaN    NaN  408    37\n",
      "5     NaN    NaN  302.0    0   153\n",
      "6     NaN    NaN    NaN  408     5\n",
      "7     NaN    NaN  303.0    0   169\n",
      "8     NaN    NaN  306.0    0    30\n",
      "9     NaN    NaN  307.0    0    16\n",
      "10    NaN    NaN  311.0    0    13\n",
      "11    NaN    NaN  312.0    0    24\n",
      "12    NaN    NaN  313.0    0    13\n",
      "13    NaN    NaN  314.0    0     1\n",
      "14    NaN    NaN  315.0    0     1\n",
      "15    NaN    NaN    NaN  414     5\n",
      "16    NaN    NaN    NaN  415     3\n",
      "17    NaN    NaN  396.0    0     9\n",
      "18    NaN    NaN  397.0  497     9\n",
      "19    NaN    NaN  398.0  498    60\n",
      "20    NaN  202.0    0.0    0     1\n",
      "21    NaN    NaN  302.0    0     1\n",
      "22    NaN  203.0    0.0    0     6\n",
      "23    NaN    NaN  301.0    0     1\n",
      "24    NaN    NaN  302.0    0     1\n",
      "25    NaN    NaN  312.0    0     1\n",
      "26    NaN    NaN  313.0    0     1\n",
      "27    NaN  204.0    0.0    0   560\n",
      "28    NaN    NaN    NaN  414     1\n",
      "29    NaN    NaN  301.0    0     4\n",
      "30    NaN    NaN    NaN  408     1\n",
      "31    NaN    NaN  302.0    0  1814\n",
      "32    NaN    NaN    NaN  408    34\n",
      "33    NaN    NaN  303.0    0    24\n",
      "34    NaN    NaN  333.0    0   126\n",
      "35    NaN    NaN  396.0    0    39\n",
      "36  199.0  203.0    0.0    0     1\n",
      "37    NaN  204.0    0.0    0   784\n",
      "各专业人数\n",
      "       s1     s2     s3   s4   num\n",
      "0     NaN    NaN  315.0    0     1\n",
      "1     NaN    NaN  313.0    0     1\n",
      "2     NaN    NaN  312.0    0     1\n",
      "3     NaN    NaN  302.0    0     1\n",
      "4     NaN    NaN  301.0    0     1\n",
      "5     NaN    NaN  302.0    0     1\n",
      "6     NaN  202.0    0.0    0     1\n",
      "7   199.0  203.0    0.0    0     1\n",
      "8     NaN    NaN  314.0    0     1\n",
      "9     NaN    NaN    NaN  414     1\n",
      "10    NaN    NaN  301.0    0     1\n",
      "11    NaN    NaN    NaN  408     1\n",
      "12    NaN    NaN    NaN  415     3\n",
      "13    NaN    NaN  301.0    0     4\n",
      "14    NaN    NaN    NaN  408     5\n",
      "15    NaN    NaN    NaN  414     5\n",
      "16    NaN  203.0    0.0    0     6\n",
      "17    NaN    NaN  397.0  497     9\n",
      "18    NaN    NaN  396.0    0     9\n",
      "19    NaN    NaN  311.0    0    13\n",
      "20    NaN    NaN  313.0    0    13\n",
      "21    NaN    NaN  307.0    0    16\n",
      "22    NaN    NaN  303.0    0    24\n",
      "23    NaN    NaN  312.0    0    24\n",
      "24    NaN    NaN  306.0    0    30\n",
      "25    NaN    NaN    NaN  408    34\n",
      "26    NaN    NaN    NaN  408    37\n",
      "27    NaN    NaN  396.0    0    39\n",
      "28    NaN    NaN  398.0  498    60\n",
      "29  101.0    0.0    0.0    0    67\n",
      "30    NaN    NaN  333.0    0   126\n",
      "31    NaN    NaN  302.0    0   153\n",
      "32    NaN    NaN  303.0    0   169\n",
      "33    NaN  204.0    0.0    0   560\n",
      "34    NaN  201.0    0.0    0   747\n",
      "35    NaN  204.0    0.0    0   784\n",
      "36    NaN    NaN  301.0    0   835\n",
      "37    NaN    NaN  302.0    0  1814\n",
      "[67, 1, 747, 835, 37, 153, 5, 169, 30, 16, 13, 24, 13, 1, 1, 5, 3, 9, 9, 60, 1, 1, 6, 1, 1, 1, 1, 560, 1, 4, 1, 1814, 34, 24, 126, 39, 1, 784]\n",
      "考场容量： [30, 30, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 30, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 30, 40, 40, 40, 40, 40, 40, 40, 40, 40, 27, 30, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 30, 40, 40, 40, 30, 25, 40, 40, 36, 30, 40, 40, 40, 40, 30, 40, 40, 40, 40, 40, 40, 40, 40, 40, 35, 30, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 30, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 30, 40, 40, 40, 30, 30, 30, 30, 30, 34, 30, 30, 26, 38, 40, 40, 40, 40, 40, 40, 40, 40, 30, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 30, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 30, 40, 37, 40, 40, 40, 40, 40, 40, 40, 40]\n",
      "考场数量： 147\n",
      "[[37, 0, 1, 2, 3], [36, 4, 5, 6, 7], [35, 8, 9, 10, 11], [34, 12, 13, 14, 15], [33, 16, 17, 18, 19], [32, 20, 21, 22, 23], [31, 24, 25, 26], [30, 27, 28, 29]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = None\n",
    "# 分组算法\n",
    "# pd.set_option('display.max_rows',200)\n",
    "# StuNum = np.loadtxt(\"classfier6127.txt\")\n",
    "aa=pd.read_excel(\"classfier6105.xlsx\").iloc[:,:5]\n",
    "aa.columns=['s1','s2','s3','s4','num']\n",
    "print(aa)\n",
    "# 对txt文件的数据排序，方便后面索引对应\n",
    "print(\"各专业人数\")\n",
    "print(aa.sort_values(by='num',axis=0).reset_index(drop=True))\n",
    "StuNum = pd.read_excel(\"classfier6105.xlsx\",header=None).iloc[:,4].tolist()[1:]\n",
    "print(StuNum)\n",
    "\n",
    "# 设置参数：教室最多可容纳人数、考场允许最大专业数量\n",
    "max_student=groups1.get_group(6105)[\"renshu\"].tolist()\n",
    "print(\"考场容量：\",max_student)\n",
    "print(\"考场数量：\",len(max_student))\n",
    "max_subject=5\n",
    "# 存放分组结果\n",
    "groups = []\n",
    "\n",
    "# 这里还没有考虑取余的情况\n",
    "for i in range(len(StuNum)):\n",
    "    StuNum[i] = StuNum[i] % 30\n",
    "\n",
    "StuNum.sort()\n",
    "# print(len(StuNum))\n",
    "start = 0\n",
    "end = len(StuNum)-1\n",
    "classroom = 0\n",
    "while(start<end and classroom<len(max_student)):\n",
    "    class_subject = []#用来存储人数对应的索引，输出的就是这个，和上面txt文件的输出对应\n",
    "    class_sum = StuNum[end]#每次循环初始，让sum等于尾指针指向的数\n",
    "    subject = 1\n",
    "    class_subject.append(end)\n",
    "    # 人数不超过教室容量、专业不超过教室容量、专业还未分完\n",
    "    while(class_sum<max_student[classroom] and subject<max_subject and start<end):\n",
    "        class_sum = class_sum + StuNum[start]\n",
    "        class_subject.append(start)\n",
    "        start = start+1\n",
    "        subject = subject+1\n",
    "    end = end-1\n",
    "    classroom+=1\n",
    "    groups.append(class_subject)\n",
    "\n",
    "print(groups)\n",
    "print(len(groups))\n",
    "# 下面的数字是不同袋子的编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classfier6103.txt', 'classfier6105.txt', 'classfier6107.txt', 'classfier6111.txt', 'classfier6112.txt', 'classfier6113.txt', 'classfier6114.txt', 'classfier6115.txt', 'classfier6116.txt', 'classfier6117.txt', 'classfier6118.txt', 'classfier6122.txt', 'classfier6124.txt', 'classfier6125.txt', 'classfier6127.txt', 'classfier6128.txt', 'classfier6129.txt', 'classfier6130.txt', 'classfier6131.txt', 'classfier6133.txt', 'classfier6134.txt', 'classfier6136.txt', 'classfier6138.txt', 'classfier6139.txt', 'classfier6140.txt', 'classfier6141.txt', 'classfier6142.txt', 'classfier6143.txt', 'classfier6144.txt', 'classfier6145.txt', 'classfier6146.txt', 'classfier6147.txt', 'classfier6148.txt', 'classfier6149.txt', 'classfier6150.txt', 'classfier6151.txt', 'classfier6152.txt', 'classfier6153.txt', 'classfier6154.txt', 'classfier6156.txt', 'classfier6157.txt', 'classfier6158.txt', 'classfier6159.txt', 'classfier6160.txt', 'params.txt']\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 6 fields in line 804, saw 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5908\\1677713207.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# header=None表示没有列标签\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mStuNum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gb2312'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;31m# print(StuNum)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1702\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1703\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1704\u001b[1;33m                 \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1705\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1706\u001b[0m                 )\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 6 fields in line 804, saw 8\n"
     ]
    }
   ],
   "source": [
    "# 分组算法\n",
    "import os\n",
    "list1 = []\n",
    "names = os.listdir(\"./\")\n",
    "for name in names:\n",
    "    if name.endswith('.txt'):\n",
    "        list1.append(name)\n",
    "print(list1)\n",
    "\n",
    "summ=0\n",
    "for j in list1:\n",
    "    # 读取文件并定位到人数一列\n",
    "    if j=='classfier6127.txt':\n",
    "        print(j)\n",
    "        # header=None表示没有列标签\n",
    "    StuNum = pd.read_csv(j,encoding='gb2312',header=None).iloc[:,0]\n",
    "    # print(StuNum)\n",
    "\n",
    "    # 设置参数：教室最多可容纳人数、考场允许最大专业数量\n",
    "    max_student=30\n",
    "    max_subject=5\n",
    "    groups = []\n",
    "    dic = {}\n",
    "    # 建立原始值 和 余数的映射\n",
    "    for i in range(len(StuNum)):\n",
    "        dic[StuNum[i]] = StuNum[i] % 30\n",
    "\n",
    "    # 保存字典映射关系\n",
    "    StuNum = []\n",
    "    with open('params.txt', 'w') as f:\n",
    "        for key, value in dic.items():\n",
    "            f.write(str(key))\n",
    "            f.write(': ')\n",
    "            f.write(str(value))\n",
    "            f.write('\\n')\n",
    "            StuNum.append(value)\n",
    "\n",
    "\n",
    "    # 对余数进行排序\n",
    "    # dic = sorted(dic.items(),key=lambda x:x[1],reverse=False)\n",
    "    StuNum.sort()\n",
    "    # print(len(StuNum))\n",
    "    start = 0\n",
    "    end = len(StuNum)-1\n",
    "    while(start<end):\n",
    "        class_subject = []\n",
    "        class_sum = StuNum[end]\n",
    "        subject = 1\n",
    "        class_subject.append(end)\n",
    "        # ===================================================文件6127在这里出了问题\n",
    "        while(class_sum<max_student and subject<max_subject):\n",
    "            class_sum = class_sum + StuNum[start]\n",
    "            class_subject.append(start)\n",
    "            start = start+1\n",
    "            subject = subject+1\n",
    "        end = end-1\n",
    "        groups.append(class_subject)\n",
    "\n",
    "    print(groups)\n",
    "    print(j)\n",
    "    summ=summ+Sum_matrix(groups)\n",
    "    print(\"\\n\")\n",
    "print(summ)\n",
    "    # 下面的数字是不同袋子的编号"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
