{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\IPMIProject\\\\master test\\\\20231223.dbf' # 文件目录\n",
    "table = DBF(path, encoding='GBK')\n",
    "df = pd.DataFrame(iter(table))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理尝试\n",
    "\n",
    "allowed_values1 = ['101','109','199']\n",
    "allowed_values2 = ['201','202','203','204']\n",
    "allowed_values3 = ['301','302','303','306','307','311','312','313','314','315','333','396','397','398']\n",
    "allowed_values4 = ['408','414','415','497','498']\n",
    "df.loc[~df['ZZLLM'].isin(allowed_values1), 'ZZLLM'] = '000'\n",
    "df.loc[~df['WGYM'].isin(allowed_values2), 'WGYM'] = '000'\n",
    "df.loc[~df['YWK1M'].isin(allowed_values3), 'YWK1M'] = '000'\n",
    "df.loc[~df['YWK2M'].isin(allowed_values4), 'YWK2M'] = '000'\n",
    "df.columns = df.columns.map(str.lower)\n",
    "arr = df\n",
    "# print(arr.head(10))\n",
    "\n",
    "# [\"bmh\",\"zzllm\",\"wgym\",\"ywk1m\",\"ywk2m\",\"bkdwdm\"]\n",
    "# 取出dataframe的几列\n",
    "df1 = arr[[\"bmh\",\"zzllm\",\"wgym\",\"ywk1m\",\"ywk2m\",\"bkdwdm\"]]\n",
    "\n",
    "# 使用其中的四个属性进行分组\n",
    "df2 = df1.groupby([\"zzllm\",\"wgym\",\"ywk1m\",\"ywk2m\"]).count()\n",
    "df2.to_excel(\"classfier.xlsx\")\n",
    "\n",
    "\n",
    "# sub_DF=[arr[arr['wgymc'].isin([i])] for i in np.unique(arr['wgymc'])]\n",
    "# print(df2.head())\n",
    "# groupby后的数据要先转为dataframe，再进行索引重建，才可以保存为xlsx\n",
    "# class_arr = pd.DataFrame(df1.groupby([\"zzllmc\",\"wgymc\",\"ywk1mc\",\"ywk2mc\"]))\n",
    "# class_arr.reset_index(inplace=True)\n",
    "# class_arr.to_excel(\"res.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照外国语考点代码拆分数据\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# arr = pd.read_excel(\"tmp.xlsx\")\n",
    "list1 = arr['wgykddm'].unique()\n",
    "groups = arr.groupby(\"wgykddm\")\n",
    "for i in arr['wgykddm'].unique():\n",
    "    groups.get_group(i).to_excel(str(i)+\".xlsx\")\n",
    "# print(groups['wgykddm'])\n",
    "    # 检查数量是否相等\n",
    "# print(arr.shape)#(16383,32)\n",
    "# sum = 0;\n",
    "# for i in arr['wgykddm'].unique():\n",
    "#     df1 = pd.read_excel(str(i)+\".xlsx\")\n",
    "#     sum += df1.shape[0]\n",
    "\n",
    "# print(sum)#16383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个考点有多少专业，以及每个专业有多少人，参考属性有[\"zzllmc\",\"wgymc\",\"ywk1mc\",\"ywk2mc\",\"bkdwdm\"]\n",
    "\n",
    "for i in arr['wgykddm'].unique():\n",
    "    df1 = pd.read_excel(str(i)+\".xlsx\")\n",
    "\n",
    "    # 使用其中的四个属性进行分组,\"bkdwdm\"\n",
    "    df2 = df1.groupby([\"zzllm\",\"wgym\",\"ywk1m\",\"ywk2m\"]).count()\n",
    "    df2.to_excel(\"classfier\"+str(i)+\".xlsx\")\n",
    "\n",
    "# 结果里面bmh表示的是每个专业的人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6116' '6152' '6103' '6107' '6146' '6144' '6143' '6139' '6117' '6153'\n",
      " '6118' '6160' '6141' '6114' '6113' '6124' '6134' '6105' '6136' '6149'\n",
      " '6159' '6157' '6151' '6115' '6112' '6111' '6156' '6133' '6148' '6140'\n",
      " '6125' '6154' '6147' '6150' '6145' '6127' '6138' '6128' '6122' '6129'\n",
      " '6130' '6131' '6142' '6158']\n",
      "172888\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理、提取出每个考点，每个专业的人数\n",
    "sums = 0\n",
    "print(list1)\n",
    "for i in list1:\n",
    "    # .fillna(method=\"ffill\")向下填充\n",
    "    res = pd.read_excel(\"classfier\"+str(i)+\".xlsx\").fillna(method=\"ffill\")\n",
    "    # dataframe按各专业人数一列排序，inplace原地排序，ascending升序\n",
    "    # res.sort_values(by=\"bmh\",inplace=True,ascending=False)\n",
    "    # 取出各专业人数一列转为array\n",
    "    # 若存在控制需要填充\n",
    "    # res = res.fillna(res['bmh'].mean())\n",
    "    StuNum = res[['zzllmc','wgymc','ywk1mc','ywk2mc','bmh']]\n",
    "    np.savetxt(\"classfier\"+str(i)+\".txt\",StuNum,fmt=\"%s,%s,%s,%s,%s\",delimiter=\" \")\n",
    "    sums += res['bmh'].sum()\n",
    "\n",
    "print(sums)\n",
    "\n",
    "# classfierX.excel中的前四列可以映射到对应的专业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sum_matrix(matrix):\n",
    "    sum=0\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix[i])):\n",
    "            sum+=matrix[i][j]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "      zzllkddm zzllkcbh  renshu\n",
      "0         6103        1      30\n",
      "1         6103       10      30\n",
      "2         6103      100      30\n",
      "3         6103      101      30\n",
      "4         6103      102      30\n",
      "...        ...      ...     ...\n",
      "5420      6160      103      30\n",
      "5421      6160      104      30\n",
      "5422      6160      105      30\n",
      "5423      6160      106      30\n",
      "5424      6160      107      16\n",
      "\n",
      "[5425 rows x 3 columns]\n",
      "[30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 29, 30, 30, 30, 31, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 26, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 29, 28, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 21, 30, 30, 30, 30, 30]\n"
     ]
    }
   ],
   "source": [
    "# 统计每个考点教室所能容纳的人数\n",
    "groups1 = pd.read_excel(\"考场容量表.xls\").groupby(\"zzllkddm\")\n",
    "print(groups1.apply(lambda x:x))\n",
    "print(groups1.get_group(6103)[\"renshu\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 32, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 32, 35, 35, 35, 35, 35, 32, 36, 36, 20, 20, 32, 20, 20, 35, 30, 40, 40, 40, 35, 35, 40, 32, 35, 20, 35, 20, 30, 30, 40, 35, 35, 30, 32, 30, 35, 40, 40, 20, 35, 20, 30, 20, 40, 32, 35, 30, 20, 20, 35, 20, 30, 20, 20, 35, 32, 20, 35, 35, 35, 40, 40, 30, 40, 35, 40, 31, 42, 28, 28, 28, 28, 28, 28, 28, 28, 28, 30, 28, 28, 28, 28, 28, 40, 35, 35, 40, 30, 30, 40, 20, 40, 35, 35, 35, 30, 35, 35, 30, 32, 30, 30, 35, 35, 40, 40, 30, 30, 30, 35, 30, 30, 35, 35, 35, 40, 30, 35, 40, 40, 35, 40, 30, 30, 30, 30, 30, 34, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 21, 30, 30, 30, 30, 30, 32, 30, 30, 30, 30, 30, 30, 30, 45, 45, 45, 32, 45, 45, 45, 45, 45, 42, 40, 40, 40, 30, 32, 30, 30, 30, 30, 30, 30, 30, 40, 30, 40, 32, 40, 35, 35, 35, 35, 40, 40, 35, 35, 35, 32, 35, 40, 40, 35, 35, 35, 30, 30, 35, 35, 32, 35, 35, 40, 35, 35, 35, 35, 35, 35, 35, 32, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35]\n",
      "考场数量： [32, 32, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 32, 35, 35, 35, 35, 35, 32, 36, 36, 30, 30, 32, 30, 30, 35, 30, 40, 40, 40, 35, 35, 40, 32, 35, 30, 35, 30, 30, 30, 40, 35, 35, 30, 32, 30, 35, 40, 40, 30, 35, 30, 30, 30, 40, 32, 35, 30, 30, 30, 35, 30, 30, 30, 30, 35, 32, 30, 35, 35, 35, 40, 40, 30, 40, 35, 40, 31, 42, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 40, 35, 35, 40, 30, 30, 40, 30, 40, 35, 35, 35, 30, 35, 35, 30, 32, 30, 30, 35, 35, 40, 40, 30, 30, 30, 35, 30, 30, 35, 35, 35, 40, 30, 35, 40, 40, 35, 40, 30, 30, 30, 30, 30, 34, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 32, 30, 30, 30, 30, 30, 30, 30, 45, 45, 45, 32, 45, 45, 45, 45, 45, 42, 40, 40, 40, 30, 32, 30, 30, 30, 30, 30, 30, 30, 40, 30, 40, 32, 40, 35, 35, 35, 35, 40, 40, 35, 35, 35, 32, 35, 40, 40, 35, 35, 35, 30, 30, 35, 35, 32, 35, 35, 40, 35, 35, 35, 35, 35, 35, 35, 32, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35]\n",
      "剩余教室数量： 13\n",
      "    zzllm   wgym  ywk1m  ywk2m  Unnamed: 0\n",
      "28  199.0  204.0    0.0      0           0\n",
      "20    NaN  204.0    0.0      0           0\n",
      "6     NaN    NaN  306.0      0           0\n",
      "18    NaN  202.0    0.0      0           1\n",
      "13    NaN    NaN    NaN    414           1\n",
      "12    NaN    NaN  315.0      0           1\n",
      "21    NaN    NaN  301.0      0           2\n",
      "7     NaN    NaN  307.0      0           2\n",
      "22    NaN    NaN    NaN    408           3\n",
      "19    NaN  203.0    0.0      0           3\n",
      "14    NaN    NaN    NaN    415           3\n",
      "10    NaN    NaN  313.0      0           3\n",
      "11    NaN    NaN  314.0      0           4\n",
      "8     NaN    NaN  311.0      0           4\n",
      "2     NaN    NaN  301.0      0           5\n",
      "9     NaN    NaN  312.0      0           7\n",
      "5     NaN    NaN  303.0      0           7\n",
      "23    NaN    NaN  302.0      0           9\n",
      "0   101.0    0.0    0.0      0          12\n",
      "15    NaN    NaN  396.0      0          12\n",
      "1     NaN  201.0    0.0      0          13\n",
      "17    NaN    NaN  398.0    498          15\n",
      "26    NaN    NaN  333.0      0          17\n",
      "3     NaN    NaN    NaN    408          18\n",
      "24    NaN    NaN    NaN    408          19\n",
      "27    NaN    NaN  396.0      0          22\n",
      "16    NaN    NaN  397.0    497          24\n",
      "25    NaN    NaN  303.0      0          25\n",
      "4     NaN    NaN  302.0      0          28\n",
      "29 35\n",
      "31 35\n",
      "30 32\n",
      "32 35\n",
      "35 35\n",
      "34 35\n",
      "29 35\n",
      "27 35\n",
      "26 35\n",
      "专业序号 [[28, 0, 1, 2, 3], [27, 4, 5, 6, 7], [26, 8, 9], [25, 10, 11, 12], [24, 13, 14, 15], [23, 16, 17], [22, 18], [21, 19], [20, 20]]\n",
      "教室容量 [35, 35, 32, 35, 35, 35, 35, 35, 35]\n",
      "学生实际数量： [29, 31, 30, 32, 35, 34, 29, 27, 26]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = None\n",
    "# 分组算法\n",
    "# pd.set_option('display.max_rows',200)\n",
    "StuNum = pd.read_excel(\"classfier6111.xlsx\")\n",
    "# print(StuNum.shape[0])\n",
    "# aa=pd.read_excel(\"classfier6105.xlsx\").iloc[:,:5]\n",
    "# aa.columns=['s1','s2','s3','s4','num']\n",
    "# print(aa.sort_values(by='num',axis=0).reset_index(drop=True))\n",
    "# 对txt文件的数据排序，方便后面索引对应\n",
    "# print(\"各类别人数\")\n",
    "# 统计考点各考场容量\n",
    "max_student=groups1.get_group(6111)[\"renshu\"].tolist()\n",
    "print(max_student)\n",
    "for i in range(len(max_student)):\n",
    "    if(max_student[i]<30):\n",
    "        max_student[i]=30\n",
    "# print(\"考场容量：\",sum(max_student))\n",
    "print(\"考场数量：\",max_student)\n",
    "# print(\"考生总数：\",sum(StuNum.iloc[:,4]))\n",
    "# print(StuNum)\n",
    "# print(StuNum.iloc[4,4])\n",
    "for i in range(0,StuNum.shape[0]):\n",
    "    # print(StuNum.iloc[i,4])\n",
    "    while StuNum.iloc[i,4] >= 30:\n",
    "        StuNum.iloc[i,4] = StuNum.iloc[i,4] - max_student[0]\n",
    "        if StuNum.iloc[i,4] < 0:\n",
    "            StuNum.iloc[i,4] = 0\n",
    "        del max_student[0]\n",
    "print(\"剩余教室数量：\",len(max_student))\n",
    "# print(max_student)\n",
    "\n",
    "# 设置参数：教室最多可容纳人数、考场允许最大专业数量\n",
    "max_subject=5\n",
    "# 存放分组结果\n",
    "groups = []\n",
    "roomV = []\n",
    "stusum = []\n",
    "\n",
    "# 这里还没有考虑取余的情况\n",
    "\n",
    "StuNum.sort_values(by=\"Unnamed: 0\" , inplace=True, ascending=True)\n",
    "print(StuNum.iloc[:,:5])\n",
    "StuNum = StuNum.iloc[:,4].values\n",
    "start = 0\n",
    "end = len(StuNum)-1\n",
    "classroom = 0\n",
    "class_sum = 0\n",
    "while(start<=end and classroom<len(max_student)):\n",
    "    class_subject = []#用来存储人数对应的索引，输出的就是这个，和上面txt文件的输出对应\n",
    "    class_sum = StuNum[end]#每次循环初始，让sum等于尾指针指向的数\n",
    "    subject = 1\n",
    "    class_subject.append(end)\n",
    "    # 人数不超过教室容量、专业不超过教室容量、专业还未分完\n",
    "    while(class_sum+StuNum[start]<=max_student[classroom] and subject<max_subject and start<=end):\n",
    "        class_sum = class_sum + StuNum[start]\n",
    "        class_subject.append(start)\n",
    "        start = start+1\n",
    "        subject = subject+1\n",
    "    print(class_sum,max_student[classroom])\n",
    "    end = end-1\n",
    "    stusum.append(class_sum)\n",
    "    roomV.append(max_student[classroom])\n",
    "    classroom+=1\n",
    "    groups.append(class_subject)\n",
    "\n",
    "print(\"专业序号\",groups)\n",
    "print(\"教室容量\",roomV)\n",
    "print(\"学生实际数量：\",stusum)\n",
    "# 下面的数字是不同袋子的编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classfier6103.txt', 'classfier6105.txt', 'classfier6107.txt', 'classfier6111.txt', 'classfier6112.txt', 'classfier6113.txt', 'classfier6114.txt', 'classfier6115.txt', 'classfier6116.txt', 'classfier6117.txt', 'classfier6118.txt', 'classfier6122.txt', 'classfier6124.txt', 'classfier6125.txt', 'classfier6127.txt', 'classfier6128.txt', 'classfier6129.txt', 'classfier6130.txt', 'classfier6131.txt', 'classfier6133.txt', 'classfier6134.txt', 'classfier6136.txt', 'classfier6138.txt', 'classfier6139.txt', 'classfier6140.txt', 'classfier6141.txt', 'classfier6142.txt', 'classfier6143.txt', 'classfier6144.txt', 'classfier6145.txt', 'classfier6146.txt', 'classfier6147.txt', 'classfier6148.txt', 'classfier6149.txt', 'classfier6150.txt', 'classfier6151.txt', 'classfier6152.txt', 'classfier6153.txt', 'classfier6154.txt', 'classfier6156.txt', 'classfier6157.txt', 'classfier6158.txt', 'classfier6159.txt', 'classfier6160.txt', 'params.txt']\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 6 fields in line 804, saw 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5908\\1677713207.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# header=None表示没有列标签\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mStuNum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gb2312'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;31m# print(StuNum)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1702\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1703\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1704\u001b[1;33m                 \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1705\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1706\u001b[0m                 )\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 6 fields in line 804, saw 8\n"
     ]
    }
   ],
   "source": [
    "# 分组算法\n",
    "import os\n",
    "list1 = []\n",
    "names = os.listdir(\"./\")\n",
    "for name in names:\n",
    "    if name.endswith('.txt'):\n",
    "        list1.append(name)\n",
    "print(list1)\n",
    "\n",
    "summ=0\n",
    "for j in list1:\n",
    "    # 读取文件并定位到人数一列\n",
    "    if j=='classfier6127.txt':\n",
    "        print(j)\n",
    "        # header=None表示没有列标签\n",
    "    StuNum = pd.read_csv(j,encoding='gb2312',header=None).iloc[:,0]\n",
    "    # print(StuNum)\n",
    "\n",
    "    # 设置参数：教室最多可容纳人数、考场允许最大专业数量\n",
    "    max_student=30\n",
    "    max_subject=5\n",
    "    groups = []\n",
    "    dic = {}\n",
    "    # 建立原始值 和 余数的映射\n",
    "    for i in range(len(StuNum)):\n",
    "        dic[StuNum[i]] = StuNum[i] % 30\n",
    "\n",
    "    # 保存字典映射关系\n",
    "    StuNum = []\n",
    "    with open('params.txt', 'w') as f:\n",
    "        for key, value in dic.items():\n",
    "            f.write(str(key))\n",
    "            f.write(': ')\n",
    "            f.write(str(value))\n",
    "            f.write('\\n')\n",
    "            StuNum.append(value)\n",
    "\n",
    "\n",
    "    # 对余数进行排序\n",
    "    # dic = sorted(dic.items(),key=lambda x:x[1],reverse=False)\n",
    "    StuNum.sort()\n",
    "    # print(len(StuNum))\n",
    "    start = 0\n",
    "    end = len(StuNum)-1\n",
    "    while(start<end):\n",
    "        class_subject = []\n",
    "        class_sum = StuNum[end]\n",
    "        subject = 1\n",
    "        class_subject.append(end)\n",
    "        # ===================================================文件6127在这里出了问题\n",
    "        while(class_sum<max_student and subject<max_subject):\n",
    "            class_sum = class_sum + StuNum[start]\n",
    "            class_subject.append(start)\n",
    "            start = start+1\n",
    "            subject = subject+1\n",
    "        end = end-1\n",
    "        groups.append(class_subject)\n",
    "\n",
    "    print(groups)\n",
    "    print(j)\n",
    "    summ=summ+Sum_matrix(groups)\n",
    "    print(\"\\n\")\n",
    "print(summ)\n",
    "    # 下面的数字是不同袋子的编号"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
